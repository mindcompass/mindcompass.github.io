---
title: 멀티캠퍼스 파이널 프로젝트 '자연어 처리를 통한 인공지능 상담봇, MeU'
excerpt: 멀티캠퍼스에서 수행했던 파이널 프로젝트
toc: true
toc_sticky: true

categories:
  - multicampus

tags:
- 멀티캠퍼스
- python	
- Tenssorflow
- 
use_math: true
last_modified_at: 2020-07-19
---

<br>

<br>

벌써 멀티캠퍼스를 수료한지 1달이 다 되어 갑니다. 정신없이 취업준비와 새로운 직장에 적응하면서 중요한 멀티캠퍼스의 마지막 프로젝트에 대한 글을 남기지 않고 있었네요.

더 시간이 지나면 앞으로 영영 남기지 많을 것 같아서, 오늘 마음 먹고 블로그를 작성합니다.

<br>

다른 프로젝트처럼 집에 있는 synology nas에 프로젝트를 배포하려고 했는데, 텐서플로우가  ATOM CPU에서 작동하지 않아서 자연어처리 및 언어모델(챗봇) 기능이 제대로 작동하지 않습니다. 물론 로컬 PC나 노트북에서는 잘 작동합니다. 아래는 파이널 프로젝트 메인페이지입니다.

[상담챗봇 미유 사이트 바로가기](http://selfcompass.synology.me:7007) 

그냥 들어가고 싶은 분은 id에 kyuhyun과 password에 각각 123를 입력해주세요. 

![Imgur](https://i.imgur.com/AiDXoX6.png)







## 1. 인공지능 상담챗봇 MeU 개요

**가. MeU의 개발목표와 방향은?**

팀원들과 설정했던  파이널 프로젝트의 가장 큰 목적은 언어모델에 대한 이해였습니다. 멀티캠퍼스 수업에서는 LSTM을 통해 텍스트에 대한 감정분석 정도까지 수행했습니다. 하지만 최신 언어모델은 ATTENTION, TRANSFORMER, BERT 또 최근 GPT2, ALBERT까지 발전하는 속도가 상상을 초월합니다.



4주 정도 프로젝트 주제를 선정하는 준비기간이 있었습니다. 이 기간 동안은 수업을 들으면서 틈틈히 프로젝트를 주제와 진행방향에 대해서 논의하는 시간이었고, 주말에 외부 전문가분들이 오셔서 멘토 시간을 가졌습니다. 

그리고 실제 파이널 프로젝트 개발기간을 위해 주어진 기간은 약 5주간 이었습니다.

대부분의 기간은 인공지능 언어모델을 이해하고 구현해보는데 활용했습니다.

결과적으로 개발한 구현 서비스는 총 4가지 였습니다.

- 언어모델을 통해 정서적 대화를 수행하는 챗봇(MeU 챗봇) (메인프로그램)
- 시나리오를 통한 대화(MeU 챗봇)
- 상담질문카드 & 감정일기(feat 텍스트마이닝)
- BERT기술을 활용한 챗봇(Bert 챗봇)



![Imgur](https://i.imgur.com/Rp8VyzI.png)



메인 프로그램인 MeU를 개발하기 위해서 현재 개발된 유사한 기능의 챗봇을 찾아서 분석하는 과정을 거쳤습니다. 

![Imgur](https://i.imgur.com/jpm12DI.png)



**나. 어떤 기술이 쓰였나요?**

개발하는데 아래 기술들이 사용되었습니다. 

Python Tensorflow

Keras

KoNLPy(형태소 분석기 Mecab, Okt 사용)

Python Django (메인 프로그램 서버)

Python Flask(인공지능 API서버 활용)

MySQL(개인정보 처리,상담카드, 챗봇 대화 저장 )

HTML5/CSS3 

JAVASCRIPT(jQuery) 

AJAX

Bootstrap4.0

<br>

<br>

## 2. 상담챗봇 MeU 기능 안내



<br>

**가. Main화면**

주소를 치고 들어가면 가장 먼저 있는 항목입니다. 

Signup, Signin을 통해 자신의 이름과 비번을 직접 넣어 로그인을 할 수 있습니다. 

상단에 메뉴바가 있고, 스크롤을 내리면 조원들을 소개하는 글이 있습니다.

![Imgur](https://i.imgur.com/AiDXoX6.png)

![Imgur](https://i.imgur.com/BYSYGI6.png)

<br>

**나. 챗봇 MeU 메인 화면(언어모델+ 시나리오)**

처음 시작하면 간단한 자기 소개가 이어지고, 연예, 취업 관련 시나리오를 통해 대화를 할 지, 아니면 학습한 언어모델을 통해 <일상대화>를 수행할지를 선택합니다.

아래 그림에서 나온 MeU의 답변은 실제 언어모델을 통해 산출된 결과입니다. 

MeU의 언어모델로 최종 선정한 모델은 Attention입니다. Transformer모델과 비교했을 때, 근소한 차이로 더 좋은 결과가 나와서 선정하게 되었습니다. 

![Imgur](https://i.imgur.com/fmT8HRP.png)



![Imgur](https://i.imgur.com/GIeDooy.png)

<br>

**다. 상담질문카드 & 감정일기(feat 텍스트마이닝)**

상담질문카드나 감정일기도 MeU의 챗봇 인터페이스를 통해 서비스가 제공됩니다.

상담질문카드는 타로카드 형식에 착안하여 카드를 선택하면 해당되는 질문을 제공합니다.

감정일기는 하루에 한번씩 내 감정을 정리하는 일기를 작성할 수 있습니다. 

마이페이지에 들어가면 그 결과를 워드클라우드 형태로 디자인 된 형태로 보여줍니다. MeU가 고양이이기 때문에 고양이 얼굴모양으로 형태를 구성했습니다.

![Imgur](https://i.imgur.com/ynFl7mQ.png)

![Imgur](https://i.imgur.com/fop7GCn.png)

<br>

**라. BERT기술을 활용한 챗봇(Bert 챗봇)**

BERT는 현실적으로 다양한 테스트를 하지 못했습니다. Google에서 제공하는multilingual BERT를 가져와서 korquad 데이터를 학습해서 기계독해 모델을 만들었습니다. 

어플리케이션을 재미있게 만들기 위해서 트와이스에 대한 정보를 미리 저장해두어서 트와이스에 대한 질문을 하면 해당 답을 제공하는 형태로 서비스를 만들었습니다. 

![Imgur](https://i.imgur.com/AiehMbT.png)



<br>

## 3. MeU프로젝트 기술 구현 원리

다른 프로젝트보다 더 많은 에너지를 쏟아부었기 때문에 단순히 기능만 설명하는 것보다 그 기능을 어떻게 구현했는지를 파악하면 좋을 것 같습니다.



**가. 구현한 언어모델의 특성**

챗봇 MeU을 구현하기 위해 자연어 처리 모델인 SEQ2SEQ, Attention, Transformer, Bert를 학습시켜 보았고, 평가를 통해 하나의 모델을 선정하였습니다.

SEQ2SEQ모델은 순환신경망으로 이루어진 인코더와 디코더로 구성되어 있습니다. 인코더는 입력문장의 모든 단어를 순차적으로 입력받아 하나의 벡터로 만들고, 디코더는 이 벡터를 받아 답변을 예측합니다. 이러한 문장의 정보를 가지는 이 벡터를 context vector라고 합니다. SEQ2SEQ는 하나의 고정된 크기의 벡터에 입력문장의 모든 정보를 압축하므로 정보의 손실이 발생한다는 단점이 있습니다.

![Imgur](https://i.imgur.com/NHBghCW.png)



SEQ2SEQ의 문제를 해결하기 위한 방법으로 Attention 기법을 추가하였습니다. Attention 모델은 context 벡터 뿐만 아니라 각각의 LSTM의 output 벡터를 디코더로 함께 전달합니다. 디코더는 각각의 output 벡터를 이용하여 현재 자신과 비교하여 주목해야할 입력 단어가 무엇인지 알아내고 반영할 수 있습니다.

Attention모델은 SEQ2SEQ보다 정확도를 높일 수 있지만, 여전히 순환신경망으로 인한 학습속도가 느리다는 단점이 존재합니다.

![Imgur](https://i.imgur.com/DEEOcx9.png)

Transformer는 구글에서 발표한 논문인 'Attention is all you need(2017)'에서 제안된 모델로, 순환신경망을 없애 학습속도가 매우 빠릅니다. 인코더 디코더는 attention만으로 이루어져 있으며, 입력단어의 순서를 반영하기 위해 positional encoding을 사용합니다.

![Imgur](https://i.imgur.com/RdSKoNl.png)

우리는 Transformer를 활용한 Bert모델 구현하여 기계독해 모델을 구현해 보았습니다. 미리 학습된 구글 Multilingual Bert 모델을 fine-tunning하고 korquad 데이터를 학습하여 정보처리봇을 구현하는데 사용하였습니다.

![Imgur](https://i.imgur.com/gi877im.png)

<br>

**나. 모델에 사용한 데이터와 모델 평가방법**

학습 모델에 사용한 데이터는 아래 3가지 출처의 데이터를 사용했습니다.

원 자료를 직접 사용한 것은 아니고, 몇가지 전처리 과정을 통해 사용했습니다. 모델의 데이터는 AI hub와 github를 통해 수집하였으며, 질문-답 형식으로 되어있는 3만개를 선택하였습니다.

![Imgur](https://i.imgur.com/myTg58c.png)



성능이 가장 좋은 모델을 선택하기 위해 Transformer와 Attention 모델에 데이터의 종류, 형태소 분석기, 단어 임베딩 방법을 바꿔가며 13개의 모델을 학습시켰습니다. 모델 평가는 정답이 정해져 있지 않는 챗봇의 특성을 고려하여, 모든 팀원이 테스트셋의 예측값에 점수를 매겨 자체평가를 진행하였습니다.

감성적 대화임으로 모델의 평가는 사람이 실제 체감하는 질적 수준과 객관적 평가 지표를 모두 활용하여 진행했습니다. 

조원 5명이 모델에 대해 블라인드된 상태에서 50개의 질문에 대한 답변을 직접 평가했습니다.

아래는 실제 13개의 모델의 답변을 조원들이 평가한 결과입니다.

![Imgur](https://i.imgur.com/bT6PuQE.png)

   

![Imgur](https://i.imgur.com/aoxKyu5.png)

MAPE 오차률을 객관적 평가 지표로 사용하였습니다. 그 결과 자체평가가 가장 높고 MAPE가 가장 낮은 3차가공 데이터를 활용한 Attention모델을 선정하였습니다.

<br>

**다.구현한 모델(Attention)의 작동 원리**

이번에는 선정한 모델이 동작하는 원리를 설명하겠습니다. 만약 그림과 같이 '오늘 피곤하다'라는 문장이 입력되면 Mecab 형태소 분석기에 의해 '오늘','피곤','하다'로 쪼개어 지게 됩니다. 이러한 각각의 형태소는 차례대로 LSTM에 들어가 context벡터와 hidden state를 출력하고, 이 값은 모두 디코더로 전달됩니다. 디코더는 이 값을 토대로 첫번째 단어인 '휴식'을 예측하는데, 여기서 중요한 것은 예측값인 '휴식'이 다시 디코더의 입력값으로 들어간다는 것입니다. 그러면 디코더는 '휴식'을 입력받아 '휴식' 다음 단어인 '을'을 예측하게 됩니다. '을'은 다시 디코더의 입력값으로 들어가고, 이 과정은 디코더가 'end'태그를 출력할 때까지 반복합니다.

![Imgur](https://i.imgur.com/NKVRAH9.png)

앞서 Attention 모델은 context 벡터뿐만 아니라 hidden state를 전달함으로서 예측시에 어떤 단어 값에 집중해야 하는지 알 수 있게 된다고 언급하였습니다. 그러면 디코더에서 이 정보들을 가지고 어떻게 출력값을 예측하는지 알아보도록 하겠습니다.

구글의 embedding projector 사이트는 다차원 벡터를 3차원으로 시각화하여 보여주는 기능을 제공합니다. 해당 그래프는 저희 인코더 모델에 30개의 문장을 넣어 만든 context벡터를 3차원으로 시각화한 것입니다. '피곤하다', '오늘따라 더 피곤하다'같은 피곤을 키워드로 한 문장들이 비슷한 위치에 놓여있는 것을 보실 수 있습니다. 이렇게 context 벡터의 값이 유사하다는 의미는 이 문장들이 디코더에서 동일한 답변을 얻을 가능성이 크다는 것을 의미합니다.

![Imgur](https://i.imgur.com/xpQghrv.png)

Attention값에 대해 살펴보도록 하겠습니다. 해당 그래프는 두 문장에 대한 Attention가중치값을 시각화한 것으로, 가중치가 클수록 밝은 색상으로 표현됩니다. ‘심심하다’와 ‘퇴근하다’를 보시면 ‘하다’와 ‘이다’가 아닌 핵심키워드인 ‘심심’과 ‘퇴근’에 집중된 것을 보실 수 있습니다. 디코더는 이 Attention값을 참고하여 대답을 예측합니다.

![Imgur](https://i.imgur.com/MdWIVHw.png)

Attention 값의 활용을 보기 위해서 예시 하나를 보도록 하겠습니다. 

'어제 공부했더니 피곤하다'의 context 벡터는 왼쪽 그림에서 볼 수 있듯이 '배고파'와 유사성이 가장 높으며, '피곤'을 키워드로 한 문장은 순위권에 보이지 않습니다.

 만약 이러한 context 벡터만을 이용하여 출력값을 예측했다면 엉뚱한 대답이 나왔을 것입니다. 하지만 오른쪽의 Attention을 시각화한 그래프를 보시면 '피곤'에 집중하고 있는 모습을 보실 수 있습니다. 이렇게 어텐션값을 통해 디코더는 올바른 문장을 예측할 수 있었습니다.

![Imgur](https://i.imgur.com/0wR41te.png)

<br>

**라.웹과 DB설계**

중앙 서버는 Django Framework를 사용했습니다. 자연어처리 전용 웹서버(Flask)를 따로 구축한것이 특징이며 Django에서 직접 통신합니다. Database는 MySQL을 사용했고 Django와 연동합니다. Chatbot 관련 웹 구현은 jQuery, WEB과 Server간 통신은 AJAX를 활용했습니다. DB내역을 불러오고 출력하는 과정은 모두 Django에서 제공하는 ORM과 Templates 을 사용했습니다

![Imgur](https://i.imgur.com/YxXfI1v.png)





총 5가지 테이블을 활용했습니다. 로그인관련 정보를 저장하는 Member, 상담질문 내역이 저장되어 있는 Question, 이에 대한 사용자 답변이 저장되는 Answer, 각 사용자별 감정일기 내용을 저장하는 Diary_answer, 추후에 자연어처리 자료로 사용하기 위해 Log를 남기는 Chat_data가 있습니다.

![Imgur](https://i.imgur.com/IDAfXzx.png)

사용자가 채팅창을 통해 하고싶은 말을 입력하면 AJAX 통신을 통해 Django에 해당 Message가 전달됩니다. 이 후 Django의 conversation def에서 Flask 함수에 해당 Message를 전달하고 이에 대한 자연어처리 응답을 받게 됩니다. 기록을 남기기 위해 Djanog에서 제공하는 ORM 을 활용하여 DB를 저장 하고 다시 AJAX 통신의 응답 값을 WEB에 전달 하면 출력하는 구조 입니다.

![Imgur](https://i.imgur.com/uheS6B6.png)



WEB 사용자 입력 ➜ Django 자연어 처리 요청 ➜ Flask API 응답 ➜ Django DB 저장 및 web 전달 ➜ WEB 출력

<br>

## 4. 프로젝트를 마치며

항상 모든 일이 그렇지만 결과에 대한 뿌듯함과 아쉬움이 공존합니다.

처음부터 프로젝트 목표가 명확했고, 팀원들과 캐미가 잘 맞아서 프로젝트를 수행하는데 큰 어려움은 없었고, 많은 것을 배울 수 있었습니다.

프로젝트가 이전 프로젝트와 달리 많은 기능과 작업량을 포함하고 있었기 때문에 저는 전체 프로젝트 기획과 언어모델에 집중할 수밖에 없었던 것도 아쉬움이 남습니다. 사실 프론트나 벡엔드쪽 작업도 파이널 프로젝트에서 많이 하고 싶긴 했습니다. 

그밖에 모델과 서비스 품질에 대한 평가는 다소 아쉽습니다. 

최신 인공지능 모델을 사용하면 뭔가 마법같은 일이 발생해서 정말 정서적 소통이 가능한 그런 챗봇을 만들 수도 있겠다는 막연한 상상이 있었지만, 현실은 그렇지 않았습니다. 

간단한 위로 기능은 수행할 수 있었지만, 입력하는 문장의 뜻이 모호하거나 학습 데이터셋에 없는 정보가 들어오면 답변의 문법이 깨지거나 엉뚱한 답변이 출력되는 것이 사실입니다. 

그래도 몰랐던 인공지능의 언어모델을 경험할 수 있었던 것 만으로 나름 보람된 프로젝트였습니다. 

멀티캠퍼스 수업의 마지막날은 공교롭게도 제 생일 날이었습니다. 

생일이여서 운이 좋아서 인지 프로젝트 우수상, 개인 성적부분 최우수상을 받았습니다. 

늦은 나이에 회사를 그만두고 참여한 국비지원 교육이였기 때문에 좀 더 열심히 참여했기에 좋은 결과가 있었던거 같습니다.    

 ![Imgur](https://i.imgur.com/GJ9AdpD.png)



인공지능과 데이터분석에 대한 공부는 앞으로 꾸준히 해나가길 기대하며, 이번 글을 마치겠습니다. 